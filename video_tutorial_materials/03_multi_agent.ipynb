{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop (HITL) Multi-Agent Loop Workflow\n",
    "\n",
    "In this notebook, we'll extend the HITL agent loop workflow to support multiple agents. This means keeping track of an active speaker, having a step to decide the active speaker, and giving agents the ability to hand off control to another agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "This remains the same as in the previous notebook -- except now, we will be making use of the name and description fields to help with selecting the active speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field,ConfigDict\n",
    "\n",
    "from llama_index.core.tools import BaseTool\n",
    "\n",
    "class AgentConfig(BaseModel):\n",
    "    \"\"\"Used to configure an agent.\"\"\"\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    system_prompt: str | None = None\n",
    "    tools: list[BaseTool] | None = None\n",
    "    tools_requiring_human_confirmation: list[str] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need multiple agents for our multi-agent workflow, we will need to define multiple agent configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Used to add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Used to multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "add_two_numbers_tool = FunctionTool.from_defaults(fn=add_two_numbers)\n",
    "multiply_two_numbers_tool = FunctionTool.from_defaults(fn=multiply_two_numbers)\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    name=\"Addition Agent\",\n",
    "    description=\"Used to add two numbers together.\",\n",
    "    system_prompt=\"You are an agent that adds two numbers together. Do not help the user with anything else.\",\n",
    "    tools=[add_two_numbers_tool],\n",
    "    tools_requiring_human_confirmation=[\"add_two_numbers\"],\n",
    ")\n",
    "\n",
    "agent_config_2 = AgentConfig(\n",
    "    name=\"Multiplication Agent\",\n",
    "    description=\"Used to multiply two numbers together.\",\n",
    "    system_prompt=\"You are an agent that multiplies two numbers together. Do not help the user with anything else.\",\n",
    "    tools=[multiply_two_numbers_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Hand-Off\n",
    "\n",
    "In order to hand off control to another agent, we can inject a custom tool that will indicate to the workflow that it is time to switch agents.\n",
    "\n",
    "In addition, the orchestrator will need to be able to select the next active speaker using a tool as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_transfer() -> None:\n",
    "    \"\"\"Used to indicate that your job is done and you would like to transfer control to another agent.\"\"\"\n",
    "    pass\n",
    "\n",
    "def transfer_to_agent(agent_name: str) -> None: \n",
    "    \"\"\"Used to transfer the user to a specific agent.\"\"\"\n",
    "    pass\n",
    "\n",
    "request_transfer_tool = FunctionTool.from_defaults(fn=request_transfer)\n",
    "transfer_to_agent_tool = FunctionTool.from_defaults(fn=transfer_to_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Definition\n",
    "\n",
    "With our agent configuration, we can define a workflow that uses the configuration to implement a basic agent loop with HITL.\n",
    "\n",
    "This workflow will:\n",
    "- initialize the global context with passed in parameters\n",
    "- if the active speaker is not set, the orchestrator will select the active speaker\n",
    "- call the active speaker with the system prompt, tools, and chat history for that agent\n",
    "- parse the tool calls from the LLM response\n",
    "  - if there are no tool calls, the workflow will stop\n",
    "  - if there are tool calls, the workflow will execute the tool calls\n",
    "    - if the tool call requires HITL, the workflow will emit an event to transfer control to a human\n",
    "      - the human can approve or reject the tool call\n",
    "    - collect the results of the tool calls\n",
    "    - update the chat history with the tool call results\n",
    "    - loop back and call the LLM again with the updated chat history\n",
    "  - if the tool call is our request_transfer tool, the workflow will emit an event to clear the active speaker and trigger the orchestrator to select a new active speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from llama_index.core.llms import ChatMessage, LLM\n",
    "from llama_index.core.program.function_program import get_function_tool\n",
    "from llama_index.core.tools import (\n",
    "    BaseTool,\n",
    "    ToolSelection,\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Context,\n",
    ")\n",
    "from llama_index.core.workflow.events import InputRequiredEvent, HumanResponseEvent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "class ActiveSpeakerEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class OrchestratorEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ToolCallEvent(Event):\n",
    "    tool_call: ToolSelection\n",
    "    tools: list[BaseTool]\n",
    "\n",
    "\n",
    "class ToolCallResultEvent(Event):\n",
    "    chat_message: ChatMessage\n",
    "\n",
    "\n",
    "class ToolRequestEvent(InputRequiredEvent):\n",
    "    tool_name: str\n",
    "    tool_id: str\n",
    "    tool_kwargs: dict\n",
    "\n",
    "\n",
    "class ToolApprovedEvent(HumanResponseEvent):\n",
    "    tool_name: str\n",
    "    tool_id: str\n",
    "    tool_kwargs: dict\n",
    "    approved: bool\n",
    "    response: str | None = None\n",
    "\n",
    "\n",
    "class ProgressEvent(Event):\n",
    "    msg: str\n",
    "\n",
    "\n",
    "DEFAULT_ORCHESTRATOR_PROMPT = (\n",
    "    \"You are the orchestration agent.\\n\"\n",
    "    \"Your job is to decide which agent to run based on the current state of the user and what they've asked to do.\\n\"\n",
    "    \"You do not need to figure out dependencies between agents; the agents will handle that themselves.\\n\"\n",
    "    \"Here are the agents you can choose from:\\n{agent_context_str}\\n\\n\"\n",
    "    \"Here is the current user state:\\n{user_state_str}\\n\\n\"\n",
    "    \"Please assist the user and transfer them as needed.\"\n",
    ")\n",
    "DEFAULT_TOOL_REJECT_STR = \"The tool call was not approved, likely due to a mistake or preconditions not being met.\"\n",
    "\n",
    "\n",
    "class ConciergeAgent(Workflow):\n",
    "    def __init__(\n",
    "        self,\n",
    "        orchestrator_prompt: str | None = None,\n",
    "        default_tool_reject_str: str | None = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.orchestrator_prompt = orchestrator_prompt or DEFAULT_ORCHESTRATOR_PROMPT\n",
    "        self.default_tool_reject_str = (\n",
    "            default_tool_reject_str or DEFAULT_TOOL_REJECT_STR\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def setup(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> ActiveSpeakerEvent | OrchestratorEvent:\n",
    "        \"\"\"Sets up the workflow, validates inputs, and stores them in the context.\"\"\"\n",
    "        active_speaker = await ctx.get(\"active_speaker\", default=\"\")\n",
    "        user_msg = ev.get(\"user_msg\")\n",
    "        agent_configs = ev.get(\"agent_configs\", default=[])\n",
    "        llm: LLM = ev.get(\"llm\", default=OpenAI(model=\"gpt-4o\", temperature=0.3))\n",
    "        chat_history = ev.get(\"chat_history\", default=[])\n",
    "        initial_state = ev.get(\"initial_state\", default={})\n",
    "        if (\n",
    "            user_msg is None\n",
    "            or agent_configs is None\n",
    "            or llm is None\n",
    "            or chat_history is None\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"User message, agent configs, llm, and chat_history are required!\"\n",
    "            )\n",
    "\n",
    "        if not llm.metadata.is_function_calling_model:\n",
    "            raise ValueError(\"LLM must be a function calling model!\")\n",
    "\n",
    "        # store the agent configs in the context\n",
    "        agent_configs_dict = {ac.name: ac for ac in agent_configs}\n",
    "        await ctx.set(\"agent_configs\", agent_configs_dict)\n",
    "        await ctx.set(\"llm\", llm)\n",
    "\n",
    "        chat_history.append(ChatMessage(role=\"user\", content=user_msg))\n",
    "        await ctx.set(\"chat_history\", chat_history)\n",
    "\n",
    "        await ctx.set(\"user_state\", initial_state)\n",
    "\n",
    "        # if there is an active speaker, we need to transfer forward the user to them\n",
    "        if active_speaker:\n",
    "            return ActiveSpeakerEvent()\n",
    "\n",
    "        # otherwise, we need to decide who the next active speaker is\n",
    "        return OrchestratorEvent(user_msg=user_msg)\n",
    "\n",
    "    @step\n",
    "    async def speak_with_agent(\n",
    "        self, ctx: Context, ev: ActiveSpeakerEvent\n",
    "    ) -> ToolCallEvent | ToolRequestEvent | StopEvent:\n",
    "        \"\"\"Speaks with the active sub-agent and handles tool calls (if any).\"\"\"\n",
    "        # Setup the agent for the active speaker\n",
    "        active_speaker = await ctx.get(\"active_speaker\")\n",
    "\n",
    "        agent_config: AgentConfig = (await ctx.get(\"agent_configs\"))[active_speaker]\n",
    "        chat_history = await ctx.get(\"chat_history\")\n",
    "        llm = await ctx.get(\"llm\")\n",
    "\n",
    "        user_state = await ctx.get(\"user_state\")\n",
    "        user_state_str = \"\\n\".join([f\"{k}: {v}\" for k, v in user_state.items()])\n",
    "        system_prompt = (\n",
    "            agent_config.system_prompt.strip()\n",
    "            + f\"\\n\\nHere is the current user state:\\n{user_state_str}\"\n",
    "        )\n",
    "\n",
    "        llm_input = [ChatMessage(role=\"system\", content=system_prompt)] + chat_history\n",
    "\n",
    "        # inject the request transfer tool into the list of tools\n",
    "        tools = [request_transfer_tool] + agent_config.tools\n",
    "\n",
    "        response = await llm.achat_with_tools(tools, chat_history=llm_input)\n",
    "\n",
    "        tool_calls: list[ToolSelection] = llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )\n",
    "        if len(tool_calls) == 0:\n",
    "            chat_history.append(response.message)\n",
    "            await ctx.set(\"chat_history\", chat_history)\n",
    "            return StopEvent(\n",
    "                result={\n",
    "                    \"response\": response.message.content,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        await ctx.set(\"num_tool_calls\", len(tool_calls))\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            if tool_call.tool_name == request_transfer_tool.metadata.name:\n",
    "                await ctx.set(\"active_speaker\", None)\n",
    "                ctx.write_event_to_stream(\n",
    "                    ProgressEvent(msg=\"Agent is requesting a transfer. Please hold.\")\n",
    "                )\n",
    "                return OrchestratorEvent()\n",
    "            elif tool_call.tool_name in agent_config.tools_requiring_human_confirmation:\n",
    "                ctx.write_event_to_stream(\n",
    "                    ToolRequestEvent(\n",
    "                        prefix=f\"Tool {tool_call.tool_name} requires human approval.\",\n",
    "                        tool_name=tool_call.tool_name,\n",
    "                        tool_kwargs=tool_call.tool_kwargs,\n",
    "                        tool_id=tool_call.tool_id,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                ctx.send_event(\n",
    "                    ToolCallEvent(tool_call=tool_call, tools=agent_config.tools)\n",
    "                )\n",
    "\n",
    "        chat_history.append(response.message)\n",
    "        await ctx.set(\"chat_history\", chat_history)\n",
    "\n",
    "    @step\n",
    "    async def handle_tool_approval(\n",
    "        self, ctx: Context, ev: ToolApprovedEvent\n",
    "    ) -> ToolCallEvent | ToolCallResultEvent:\n",
    "        \"\"\"Handles the approval or rejection of a tool call.\"\"\"\n",
    "        if ev.approved:\n",
    "            active_speaker = await ctx.get(\"active_speaker\")\n",
    "            agent_config = (await ctx.get(\"agent_configs\"))[active_speaker]\n",
    "            return ToolCallEvent(\n",
    "                tools=agent_config.tools,\n",
    "                tool_call=ToolSelection(\n",
    "                    tool_id=ev.tool_id,\n",
    "                    tool_name=ev.tool_name,\n",
    "                    tool_kwargs=ev.tool_kwargs,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            return ToolCallResultEvent(\n",
    "                chat_message=ChatMessage(\n",
    "                    role=\"tool\",\n",
    "                    content=ev.response or self.default_tool_reject_str,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def handle_tool_call(\n",
    "        self, ctx: Context, ev: ToolCallEvent\n",
    "    ) -> ActiveSpeakerEvent:\n",
    "        \"\"\"Handles the execution of a tool call.\"\"\"\n",
    "        tool_call = ev.tool_call\n",
    "        tools_by_name = {tool.metadata.get_name(): tool for tool in ev.tools}\n",
    "\n",
    "        tool_msg = None\n",
    "\n",
    "        tool = tools_by_name.get(tool_call.tool_name)\n",
    "        additional_kwargs = {\n",
    "            \"tool_call_id\": tool_call.tool_id,\n",
    "            \"name\": tool.metadata.get_name(),\n",
    "        }\n",
    "        if not tool:\n",
    "            tool_msg = ChatMessage(\n",
    "                role=\"tool\",\n",
    "                content=f\"Tool {tool_call.tool_name} does not exist\",\n",
    "                additional_kwargs=additional_kwargs,\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            tool_output = await tool.acall(**tool_call.tool_kwargs)\n",
    "\n",
    "            tool_msg = ChatMessage(\n",
    "                role=\"tool\",\n",
    "                content=tool_output.content,\n",
    "                additional_kwargs=additional_kwargs,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            tool_msg = ChatMessage(\n",
    "                role=\"tool\",\n",
    "                content=f\"Encountered error in tool call: {e}\",\n",
    "                additional_kwargs=additional_kwargs,\n",
    "            )\n",
    "\n",
    "        ctx.write_event_to_stream(\n",
    "            ProgressEvent(\n",
    "                msg=f\"Tool {tool_call.tool_name} called with {tool_call.tool_kwargs} returned {tool_msg.content}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return ToolCallResultEvent(chat_message=tool_msg)\n",
    "\n",
    "    @step\n",
    "    async def aggregate_tool_results(\n",
    "        self, ctx: Context, ev: ToolCallResultEvent\n",
    "    ) -> ActiveSpeakerEvent:\n",
    "        \"\"\"Collects the results of all tool calls and updates the chat history.\"\"\"\n",
    "        num_tool_calls = await ctx.get(\"num_tool_calls\")\n",
    "        results = ctx.collect_events(ev, [ToolCallResultEvent] * num_tool_calls)\n",
    "        if not results:\n",
    "            return\n",
    "\n",
    "        chat_history = await ctx.get(\"chat_history\")\n",
    "        for result in results:\n",
    "            chat_history.append(result.chat_message)\n",
    "        await ctx.set(\"chat_history\", chat_history)\n",
    "\n",
    "        return ActiveSpeakerEvent()\n",
    "\n",
    "    @step\n",
    "    async def orchestrator(\n",
    "        self, ctx: Context, ev: OrchestratorEvent\n",
    "    ) -> ActiveSpeakerEvent | StopEvent:\n",
    "        \"\"\"Decides which agent to run next, if any.\"\"\"\n",
    "        agent_configs = await ctx.get(\"agent_configs\")\n",
    "        chat_history = await ctx.get(\"chat_history\")\n",
    "\n",
    "        agent_context_str = \"\"\n",
    "        for agent_name, agent_config in agent_configs.items():\n",
    "            agent_context_str += f\"{agent_name}: {agent_config.description}\\n\"\n",
    "\n",
    "        user_state = await ctx.get(\"user_state\")\n",
    "        user_state_str = \"\\n\".join([f\"{k}: {v}\" for k, v in user_state.items()])\n",
    "        system_prompt = self.orchestrator_prompt.format(\n",
    "            agent_context_str=agent_context_str, user_state_str=user_state_str\n",
    "        )\n",
    "\n",
    "        llm_input = [ChatMessage(role=\"system\", content=system_prompt)] + chat_history\n",
    "        llm = await ctx.get(\"llm\")\n",
    "\n",
    "        # convert the TransferToAgent pydantic model to a tool\n",
    "        tools = [transfer_to_agent_tool]\n",
    "\n",
    "        response = await llm.achat_with_tools(tools, chat_history=llm_input)\n",
    "        tool_calls = llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )\n",
    "\n",
    "        # if no tool calls were made, the orchestrator probably needs more information\n",
    "        if len(tool_calls) == 0:\n",
    "            chat_history.append(response.message)\n",
    "            return StopEvent(\n",
    "                result={\n",
    "                    \"response\": response.message.content,\n",
    "                    \"chat_history\": chat_history,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        tool_call = tool_calls[0]\n",
    "        selected_agent = tool_call.tool_kwargs[\"agent_name\"]\n",
    "        await ctx.set(\"active_speaker\", selected_agent)\n",
    "\n",
    "        ctx.write_event_to_stream(\n",
    "            ProgressEvent(msg=f\"Transferring to agent {selected_agent}\")\n",
    "        )\n",
    "\n",
    "        return ActiveSpeakerEvent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out!\n",
    "\n",
    "With our workflow defined, we can now try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring to agent Addition Agent\n",
      "Tool add_two_numbers requires human approval. Approving!\n",
      "Tool add_two_numbers called with {'a': 10, 'b': 10} returned 20\n",
      "-----------\n",
      "The sum of 10 + 10 is 20.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "workflow = ConciergeAgent(verbose=False)\n",
    "\n",
    "handler = workflow.run(\n",
    "    agent_configs=[agent_config, agent_config_2],\n",
    "    user_msg=\"What is 10 + 10?\",\n",
    "    chat_history=[],\n",
    "    initial_state={\"user_name\": \"Logan\"},\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        print(event.msg)\n",
    "    elif isinstance(event, ToolRequestEvent):\n",
    "        print(f\"Tool {event.tool_name} requires human approval. Approving!\")\n",
    "        # TODO: Implement your own logic to approve or reject the tool call\n",
    "        # TODO: Try to reject the tool call and see what happens!\n",
    "        handler.ctx.send_event(ToolApprovedEvent(\n",
    "            approved=True,\n",
    "            tool_name=event.tool_name,\n",
    "            tool_id=event.tool_id,\n",
    "            tool_kwargs=event.tool_kwargs,\n",
    "        ))\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the chat history is passed in each time, we will need to manage it for the next run. A useful way to do this is with a memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "memory.set(final_result[\"chat_history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets run again with chat history managed by the memory buffer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is requesting a transfer. Please hold.\n",
      "Transferring to agent Multiplication Agent\n",
      "Tool multiply_two_numbers called with {'a': 212, 'b': 121} returned 25652\n",
      "-----------\n",
      "The product of 212 * 121 is 25,652.\n"
     ]
    }
   ],
   "source": [
    "handler = workflow.run(\n",
    "    # maintain the same context as the previous run, which holds the active speaker!\n",
    "    ctx=handler.ctx,\n",
    "    agent_configs=[agent_config, agent_config_2],\n",
    "    user_msg=\"What is 212 * 121?\",\n",
    "    chat_history=memory.get(),\n",
    "    initial_state={\"user_name\": \"Logan\"},\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        print(event.msg)\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.set(final_result[\"chat_history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is requesting a transfer. Please hold.\n",
      "-----------\n",
      "The capital of Canada is Ottawa.\n"
     ]
    }
   ],
   "source": [
    "handler = workflow.run(\n",
    "    ctx=handler.ctx,\n",
    "    agent_configs=[agent_config, agent_config_2],\n",
    "    user_msg=\"What is the capital of Canada?\",\n",
    "    chat_history=memory.get(),\n",
    "    initial_state={\"user_name\": \"Logan\"},\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, ProgressEvent):\n",
    "        print(event.msg)\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "final_result = await handler\n",
    "print(final_result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "The one feature we omitted from this tutorial was handling function tools that have access to the context. You can view this implementation in `utils.py` in the [multi-agent-concierge](https://github.com/run-llama/multi-agent-concierge) repo. Essentially, this is a copy of the `FunctionTool` class from `llama-index`, but with tweaks to omit the `Context` parameter from the tool schema to hide it from the LLM.\n",
    "\n",
    "Feel free to use that repo as a starting point for your own multi-agent workflows! We are exited to see what the community builds next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mutli-agent-concierge-QdC2PJgK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
